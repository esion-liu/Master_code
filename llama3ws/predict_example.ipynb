{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ac9c7d-d5e6-4729-bdb7-63484062ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth: Fast Llama patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.988 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# laod model\n",
    "from unsloth import FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"ll3_fitting/epoch_329\",\n",
    "    max_seq_length = 4096,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfd8990-7691-4ade-beee-983c7d2b00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = '<|reserved_special_token_250|>'\n",
    "tokenizer.pad_token_id = 128255\n",
    "def prompt_generation(a_title, b_title, a_review, b_review):\n",
    "    temp = []\n",
    "    temp.append({'role': 'system', 'content': \"You are a personal judge of video game, your role is to judge which game is preferred by the user based on user's feedbacks of two games. Simply reply with the prefered game's full name, no need for explanation\"})\n",
    "    temp.append({\n",
    "        'role': 'user',\n",
    "        'content': f\"I played two games {a_title}, and {b_title}. After playing, I gave reviews for both games as follow:\\n{a_title}: {a_review}\\n{b_title}: {b_review}\\n\"\n",
    "    })\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "158f27a1-1161-406b-b048-f45f9d1414ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "You are a personal judge of video game, your role is to judge which game is preferred by the user based on user's feedbacks of two games. Simply reply with the prefered game's full name, no need for explanationuser\n",
      "\n",
      "I played two games Game 1, and Game 2. After playing, I gave reviews for both games as follow:\n",
      "Game 1: This game is good!\n",
      "Game 2: This game is a truly masterpiese!assistant\n",
      "\n",
      "Game 2\n",
      "system\n",
      "\n",
      "You are a personal judge of video game, your role is to judge which game is preferred by the user based on user's feedbacks of two games. Simply reply with the prefered game's full name, no need for explanationuser\n",
      "\n",
      "I played two games Game 1, and Game 3. After playing, I gave reviews for both games as follow:\n",
      "Game 1: This game is good!\n",
      "Game 3: This game is very good!assistant\n",
      "\n",
      "Game 3\n",
      "system\n",
      "\n",
      "You are a personal judge of video game, your role is to judge which game is preferred by the user based on user's feedbacks of two games. Simply reply with the prefered game's full name, no need for explanationuser\n",
      "\n",
      "I played two games Game 2, and Game 3. After playing, I gave reviews for both games as follow:\n",
      "Game 2: This game is a truly masterpiese!\n",
      "Game 3: This game is very goodassistant\n",
      "\n",
      "Game 2\n",
      "system\n",
      "\n",
      "You are a personal judge of video game, your role is to judge which game is preferred by the user based on user's feedbacks of two games. Simply reply with the prefered game's full name, no need for explanationuser\n",
      "\n",
      "I played two games Game 4, and Game 5. After playing, I gave reviews for both games as follow:\n",
      "Game 4: For this game, I have no time for sleeing and eating!\n",
      "Game 5: This game contains some flaws, but overall it is a good game.assistant\n",
      "\n",
      "Game 4\n"
     ]
    }
   ],
   "source": [
    "msgs = [prompt_generation('Game 1', 'Game 2', 'This game is good!', 'This game is a truly masterpiese!'),\n",
    "        prompt_generation('Game 1', 'Game 3', 'This game is good!', 'This game is very good!'),\n",
    "        prompt_generation('Game 2', 'Game 3', 'This game is a truly masterpiese!', 'This game is very good'),\n",
    "        prompt_generation('Game 4', 'Game 5', 'For this game, I have no time for sleeing and eating!', 'This game contains some flaws, but overall it is a good game.'),\n",
    "       ]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "        msgs,\n",
    "        tokenize = True,\n",
    "        padding = True,\n",
    "        truncation = False,\n",
    "        add_generation_prompt = True, # Must add for generation\n",
    "        return_tensors = \"pt\",\n",
    "    )\n",
    "\n",
    "attention_mask = (inputs != tokenizer.pad_token_id).int()\n",
    "outputs = model.generate(input_ids = inputs, max_new_tokens = 1024, attention_mask = attention_mask, use_cache = True)\n",
    "result = tokenizer.batch_decode(outputs[:], skip_special_tokens = True)\n",
    "for i in range(len(result)):\n",
    "    print(result[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
