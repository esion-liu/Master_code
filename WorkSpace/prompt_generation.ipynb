{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note will be used for prompt generation test\n",
    "\n",
    "1. summarization of critic reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# bert is not smart enough, going to use llama3 as summarizer\n",
    "model_id = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "HF_API_TOKEN = \"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\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, token=HF_API_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, token=HF_API_TOKEN)\n",
    "model = model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brief test of llama3-instruct\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a summarizer who summarize critic reviews of video game, the work is to highlight the shared view points and different view points. Also you need to summarize the distribution of their scores (0-100).\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,  29385,\n",
       "           3213,    889,  63179,   9940,   8544,    315,   2835,   1847,     11,\n",
       "            279,    990,    374,    311,  11415,    279,   6222,   1684,   3585,\n",
       "            323,   2204,   1684,   3585,     13,   7429,    499,   1205,    311,\n",
       "          63179,    279,   8141,    315,    872,  12483,    320,     15,     12,\n",
       "           1041,    570, 128009, 128006,    882, 128007,    271,  15546,    527,\n",
       "            499,     30, 128009, 128006,  78191, 128007,    271]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a summarizer who summarize critic reviews of video game, the work is to highlight the shared view points and different view points. Also you need to summarize the distribution of their scores (0-100).<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = tokenizer.decode(inputs[0], skip_special_tokens=False)\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the generation parameters\n",
    "max_new_tokens = 256\n",
    "temperature = 0.6\n",
    "top_p = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    do_sample=True,\n",
    "    eos_token_id=[tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a summarizer who summarize critic reviews of video game, the work is to highlight the shared view points and different view points. Also you need to summarize the distribution of their scores (0-100).<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who are you?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I am a summarizer, specifically designed to summarize critic reviews of video games. My task is to analyze the reviews from various critics and journalists, identify the shared viewpoints and differing opinions, and summarize the overall sentiment and scores given to the game.\n",
      "\n",
      "I'll be highlighting the common themes, praises, and criticisms found in the reviews, as well as noting any significant disagreements or controversies. Additionally, I'll provide a summary of the score distribution, ranging from 0 to 100, to give you an idea of the general consensus among critics.\n",
      "\n",
      "So, if you're looking for a comprehensive overview of what the critics are saying about a particular game, I'm here to help!<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for summarization\n",
    "class summarizer:\n",
    "\n",
    "    def __init__(self, model, tokenizer, psyconn):\n",
    "        self.module = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.conn = psyconn\n",
    "\n",
    "    def summarize_game(self, game_name, data_from_metacritic=False, detailed_steam_info=False):\n",
    "\n",
    "        steam_sql =f\"\"\"\n",
    "            SELECT description, positive_rate, developer, genes, release_date\n",
    "            FROM games\n",
    "            WHERE games.name = '{game_name}';\n",
    "        \"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(steam_sql)\n",
    "\n",
    "        description, positive_rate, developer, genes, release_date = cursor.fetchone()\n",
    "        msg = f\"Please help me analysis the game: {game_name}. {game_name} was developed by {developer}, {developer} characterizes this game with tags: {genes} and gives a short description: {description}\\n\"\n",
    "\n",
    "        if detailed_steam_info:\n",
    "            msg = msg + f\"So far, {round(positive_rate)} percent of its customers give positive reviews.\"\n",
    "\n",
    "        if data_from_metacritic:\n",
    "            meta_sql = f\"\"\"\n",
    "                SELECT game_name, AVG(score)\n",
    "                FROM meta_critic_reviews\n",
    "                WHERE game_name = '{game_name}'\n",
    "                GROUP BY game_name;\n",
    "            \"\"\"\n",
    "\n",
    "            cursor.execute(meta_sql)\n",
    "            _, avg_score = cursor.fetchone()\n",
    "            msg = msg + f\"\\nNext are some reviews from critic reviewers on metacritic. In metacritic the game get an average score of {round(avg_score)} out of 100.\\n\"\n",
    "\n",
    "            meta_sql = f\"\"\"\n",
    "                SELECT reviewer_name, score, review\n",
    "                FROM meta_critic_reviews\n",
    "                WHERE game_name = '{game_name}'\n",
    "                ORDER BY score DESC;\n",
    "            \"\"\"\n",
    "            cursor.execute(meta_sql)\n",
    "            reviews = cursor.fetchall()\n",
    "\n",
    "            # promopt messages for llama3-8B-instruct\n",
    "            prompt_messages = [\n",
    "                {\"role\": \"system\", \"content\": \"You are a summarizer who summarize critic reviews of video game into one paragraph, the work is to highlight the shared view points and different view points. Also you need to summarize the distribution of their scores (0-100).\\n\"},\n",
    "                {\"role\": \"user\", \"content\": \"Please summarize following critic reviews to video game {game_name} from Metacritic:\\n\"}\n",
    "            ]\n",
    "\n",
    "            for (reviewer, score, review_text) in reviews:\n",
    "                prompt_messages[1][\"content\"] = prompt_messages[1][\"content\"] + reviewer + \": \" + review_text + (f\" In conclusion this reviewer gives a score of {str(score)}.\\n\" if score != -100 else \" This reviewer does not give a score.\\n\")\n",
    "\n",
    "            inputs = self.tokenizer.apply_chat_template(prompt_messages, return_tensors=\"pt\", add_generation_prompt=True).to('cuda')\n",
    "            outputs = model.generate(\n",
    "                inputs,\n",
    "                max_new_tokens=384,\n",
    "                temperature=0.2,\n",
    "                top_p=0.9,\n",
    "                do_sample=True,\n",
    "                eos_token_id=[tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "            )\n",
    "\n",
    "            output = self.tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "            idx = output.find(\"<|start_header_id|>assistant<|end_header_id|>\")\n",
    "            output = output[idx:]\n",
    "            print(output)\n",
    "        cursor.close()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_conn_param = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5432',\n",
    "    'user': 'postgres',\n",
    "    'password': 'Lyc199412',\n",
    "    'database': 'steam'\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**postgres_conn_param)\n",
    "summarizer = summarizer(model, tokenizer, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here is a summary of the critic reviews for Battlefield V:\n",
      "\n",
      "**Shared viewpoints:**\n",
      "\n",
      "* Most critics agree that Battlefield V is an improvement over its predecessors, with a more refined gunplay and a new squad system that adds depth to the gameplay.\n",
      "* The game's multiplayer mode is praised for its intensity and excitement, with many critics enjoying the large-scale battles and objective-based gameplay.\n",
      "* The game's visuals and sound design are also widely praised, with many critics noting that the game is one of the most visually stunning FPS games on the market.\n",
      "\n",
      "**Different viewpoints:**\n",
      "\n",
      "* Some critics feel that the game is lacking in content, particularly at launch, with too few maps and modes available.\n",
      "* Others criticize the game's single-player campaign, which is seen as forgettable and lacking in depth.\n",
      "* A few critics note that the game is still rough around the edges, with technical issues and bugs that detract from the overall experience.\n",
      "\n",
      "**Score distribution:**\n",
      "\n",
      "* The majority of critics (around 60%) gave the game a score of 80-90, indicating a high level of quality and enjoyment.\n",
      "* Around 20% of critics gave the game a score of 70-79, indicating a good but not great experience.\n",
      "* Around 10% of critics gave the game a score of 60-69, indicating a mediocre experience.\n",
      "* A few critics gave the game a score of 50-59, indicating a poor experience.\n",
      "* One critic gave the game a score of 0, indicating a complete lack of enjoyment.\n",
      "\n",
      "Overall, Battlefield V is a well-regarded game that is praised for its gameplay, visuals, and sound design. However, some critics feel that the game is lacking in content and has some technical issues that detract from the overall experience.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "summarizer.summarize_game('Battlefield V', True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. assisstant respond with aggregation of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for assisstant response generator based on reviews from a cluster of customers\n",
    "class assisstant_response:\n",
    "\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.module = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def gen_response(self, reviews, game_name):\n",
    "\n",
    "        prompt_message = [\n",
    "            {\"role\": \"system\", \"content\": (\"You are a video game recommender, your task is to make suggestions before purchase a video game. \"\n",
    "                                           \"Your suggestion should based on reviews and status of players who purchased this game. \"\n",
    "                                           \"You should make predictions of attitude, playing time of the game. Examples like: \"\n",
    "                                           \"\\\"You probabily like this game, and will spend a lot of times on it\\\", \"\n",
    "                                           \"\\\"You won't like this game, but it is a good time killing tool if you really have nothing to do\\\".\")},\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize these reviews and playing time status (in brackets) of game: {game_name}:\\n\"}\n",
    "        ]\n",
    "\n",
    "        for i, review in enumerate(reviews):\n",
    "            prompt_message[1]['content'] = prompt_message[1]['content'] + f\"reviewer {str(i)}:\" + review\n",
    "\n",
    "        inputs = self.tokenizer.apply_chat_template(prompt_message, return_tensors=\"pt\", add_generation_prompt=True).to('cuda')\n",
    "        outputs = model.generate(\n",
    "                inputs,\n",
    "                max_new_tokens=256,\n",
    "                temperature=0.2,\n",
    "                top_p=0.9,\n",
    "                do_sample=True,\n",
    "                eos_token_id=[tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "            )\n",
    "\n",
    "        output = self.tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "        idx = output.find(\"<|start_header_id|>assistant<|end_header_id|>\")\n",
    "        output = output[idx:]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = assisstant_response(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reviews = [\n",
    "    \"At least the uninstall button works (spent little time)\",\n",
    "    \"Words cant describe how great this game is. But numbers can. 1/10 (spent little time)\",\n",
    "    \"damn, efootball and EAFC24 really go all the way down to the garbage. I miss the old PES and FIFA (spend some time)\",\n",
    "    \"\"\"2 years. People waited for TWO full years under the promise that this game was going to be groundbreaking .\n",
    "The only logical and possible explanation for how bad this game is, is that KONAMI wants to declare bunkruptcy or something.\n",
    "It's equally laughable and sad.\n",
    "They launched a \"full\" game that lacks content left and right. They even dumbed down the Game Plan settings.\n",
    "Terrible, just terrible.\n",
    "KONAMI just enjoys shooting themselves in the foot. (spent some time)\"\"\",\n",
    "    \"This is (probably) the only game my wife manages to beat me to. Game sucks, I hate it but my wife's smile and joy when she scores a goal beats all the cons this game has. (spent some time)\",\n",
    "    \"Worst football game ever. Konami, go home, you are drunk. (nearly did not spend any time)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "c:\\Users\\Liues\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:649: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Based on the reviews and playing time status, here's a summary:\n",
      "\n",
      "**Overall Attitude:** The game has received overwhelmingly negative reviews, with most reviewers expressing disappointment, frustration, and even anger towards the game's poor quality.\n",
      "\n",
      "**Playing Time:** The playing time varies, but most reviewers have spent little to some time playing the game, indicating that it may not be engaging or enjoyable for many players.\n",
      "\n",
      "**Predictions:**\n",
      "\n",
      "* You probably won't like this game, as it seems to have received widespread criticism for its poor quality and lack of content.\n",
      "* You might spend some time playing it, but it's unlikely to hold your attention for long due to its numerous flaws.\n",
      "* If you're a fan of football games, you might be disappointed by the game's poor performance and lack of innovation.\n",
      "\n",
      "Keep in mind that opinions are subjective, and some players might still find enjoyment in the game. However, based on the reviews, it seems that FIFA 2024 is not a well-regarded game.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "output = ar.gen_response(sample_reviews, \"FIFA 2024\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will generate the training dataset for the general-passive assisstant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
